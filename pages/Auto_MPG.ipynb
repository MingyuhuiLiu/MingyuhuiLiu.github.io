{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import itertools\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>accerleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  accerleration  \\\n",
       "0  18.0          8         307.0      130.0  3504.0           12.0   \n",
       "1  15.0          8         350.0      165.0  3693.0           11.5   \n",
       "2  18.0          8         318.0      150.0  3436.0           11.0   \n",
       "3  16.0          8         304.0      150.0  3433.0           12.0   \n",
       "4  17.0          8         302.0      140.0  3449.0           10.5   \n",
       "5  15.0          8         429.0      198.0  4341.0           10.0   \n",
       "6  14.0          8         454.0      220.0  4354.0            9.0   \n",
       "7  14.0          8         440.0      215.0  4312.0            8.5   \n",
       "\n",
       "   model year  origin  \n",
       "0          70       1  \n",
       "1          70       1  \n",
       "2          70       1  \n",
       "3          70       1  \n",
       "4          70       1  \n",
       "5          70       1  \n",
       "6          70       1  \n",
       "7          70       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Step 1: read in data file.\n",
    "\n",
    "Columns should be named as the following: \n",
    "\n",
    "1. mpg: continuous \n",
    "2. cylinders: multi-valued discrete \n",
    "3. displacement: continuous \n",
    "4. horsepower: continuous \n",
    "5. weight: continuous \n",
    "6. acceleration: continuous \n",
    "7. model year: multi-valued discrete \n",
    "8. origin: multi-valued discrete \n",
    "9. car name: string (unique for each instance)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "read=pd.read_csv('auto_mpg.data', delim_whitespace = True,\n",
    "               names = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"accerleration\", \"model year\", \"origin\", \"car name\"]) \n",
    "                 \n",
    "data = read.drop(['car name'], axis=1, inplace = False)\n",
    "print(data.shape)\n",
    "data.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg              False\n",
      "cylinders        False\n",
      "displacement     False\n",
      "horsepower       False\n",
      "weight           False\n",
      "accerleration    False\n",
      "model year       False\n",
      "origin           False\n",
      "dtype: bool\n",
      "\n",
      "Columns names: \n",
      "['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'accerleration', 'model year', 'origin']\n",
      "\n",
      "Type for column mpg: <class 'numpy.float64'>\n",
      "Type for column cylinders: <class 'numpy.int64'>\n",
      "Type for column displacement: <class 'numpy.float64'>\n",
      "Type for column horsepower: <class 'str'>\n",
      "Type for column weight: <class 'numpy.float64'>\n",
      "Type for column accerleration: <class 'numpy.float64'>\n",
      "Type for column model year: <class 'numpy.int64'>\n",
      "Type for column origin: <class 'str'>\n",
      "\n",
      "Index that containing special characters:\n",
      "[32, 126, 330, 336, 354, 374]\n",
      "\n",
      "(398, 8)\n",
      "(392, 8)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Step 2: Clean the data\n",
    "\n",
    "1). Noted that in the original dataset, categorical column \"origin\" is stored as numerical, I need to convert them into string. \n",
    "2). Check datatype.\n",
    "3). Drop NANs and other data that does not make sense. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Convert 'origin' column into string:\n",
    "data['origin'] = data['origin'].astype(str)\n",
    "\n",
    "# Clean data: check first if there is any NANs.\n",
    "print(data.isnull().any()) # No NAN. If there is any, comment out the following. \n",
    "#df = data.dropna(how='all')\n",
    "print()\n",
    "\n",
    "col = list(data.columns.values)\n",
    "print(\"Columns names: \\n{}\".format(col))\n",
    "print()\n",
    "\n",
    "# Check each column's type: noted that horsepower is str. \n",
    "for column in col:\n",
    "    print(\"Type for column {}: {}\".format(column, type(data[column][0])))\n",
    "    \n",
    "print()\n",
    "    \n",
    "# Check the string: I found '?' in there, which cannot be converted to numeirc. \n",
    "index_list = data['horsepower'].index[data['horsepower'] == '?'].tolist()\n",
    "print(\"Index that containing special characters:\\n{}\".format(index_list))\n",
    "print()\n",
    "print(data.shape)\n",
    "# Drop the rows with index_list generated above. \n",
    "df=data.drop(np.array(index_list))\n",
    "\n",
    "# Need to reset the index, otherwise the index are gone after the drop. \n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>accerleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.697747</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.075915</td>\n",
       "      <td>130</td>\n",
       "      <td>0.619748</td>\n",
       "      <td>-1.283618</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.082115</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.486832</td>\n",
       "      <td>165</td>\n",
       "      <td>0.842258</td>\n",
       "      <td>-1.464852</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.697747</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.181033</td>\n",
       "      <td>150</td>\n",
       "      <td>0.539692</td>\n",
       "      <td>-1.646086</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.953992</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.047246</td>\n",
       "      <td>150</td>\n",
       "      <td>0.536160</td>\n",
       "      <td>-1.283618</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.825870</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.028134</td>\n",
       "      <td>140</td>\n",
       "      <td>0.554997</td>\n",
       "      <td>-1.827320</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.082115</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>2.241772</td>\n",
       "      <td>198</td>\n",
       "      <td>1.605147</td>\n",
       "      <td>-2.008554</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.210238</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>2.480677</td>\n",
       "      <td>220</td>\n",
       "      <td>1.620452</td>\n",
       "      <td>-2.371022</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.210238</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>2.346890</td>\n",
       "      <td>215</td>\n",
       "      <td>1.571005</td>\n",
       "      <td>-2.552256</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mpg  cylinders  displacement horsepower    weight  accerleration  \\\n",
       "0 -0.697747   1.482053      1.075915        130  0.619748      -1.283618   \n",
       "1 -1.082115   1.482053      1.486832        165  0.842258      -1.464852   \n",
       "2 -0.697747   1.482053      1.181033        150  0.539692      -1.646086   \n",
       "3 -0.953992   1.482053      1.047246        150  0.536160      -1.283618   \n",
       "4 -0.825870   1.482053      1.028134        140  0.554997      -1.827320   \n",
       "5 -1.082115   1.482053      2.241772        198  1.605147      -2.008554   \n",
       "6 -1.210238   1.482053      2.480677        220  1.620452      -2.371022   \n",
       "7 -1.210238   1.482053      2.346890        215  1.571005      -2.552256   \n",
       "\n",
       "   model year origin  \n",
       "0   -1.623241      1  \n",
       "1   -1.623241      1  \n",
       "2   -1.623241      1  \n",
       "3   -1.623241      1  \n",
       "4   -1.623241      1  \n",
       "5   -1.623241      1  \n",
       "6   -1.623241      1  \n",
       "7   -1.623241      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Step 3:\n",
    "\n",
    "1. Rewrite columns into their normalized form;\n",
    "2. Convert string column to numeric column.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for column in col:\n",
    "    if column != 'horsepower' and column != 'origin':\n",
    "        mean = df[column].mean()\n",
    "        std = df[column].std()\n",
    "        df[column] = (df[column]-mean)/std\n",
    "    if column == 'horsepower':\n",
    "        for ele in range(0,len(df['horsepower'])):\n",
    "            df[column][ele] = (float(df[column][ele]))\n",
    "\n",
    "\n",
    "df.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>accerleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.697747</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.075915</td>\n",
       "      <td>0.663285</td>\n",
       "      <td>0.619748</td>\n",
       "      <td>-1.283618</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.082115</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.486832</td>\n",
       "      <td>1.57258</td>\n",
       "      <td>0.842258</td>\n",
       "      <td>-1.464852</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.697747</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.181033</td>\n",
       "      <td>1.18288</td>\n",
       "      <td>0.539692</td>\n",
       "      <td>-1.646086</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.953992</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.047246</td>\n",
       "      <td>1.18288</td>\n",
       "      <td>0.536160</td>\n",
       "      <td>-1.283618</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.825870</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>1.028134</td>\n",
       "      <td>0.923085</td>\n",
       "      <td>0.554997</td>\n",
       "      <td>-1.827320</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.082115</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>2.241772</td>\n",
       "      <td>2.42992</td>\n",
       "      <td>1.605147</td>\n",
       "      <td>-2.008554</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.210238</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>2.480677</td>\n",
       "      <td>3.00148</td>\n",
       "      <td>1.620452</td>\n",
       "      <td>-2.371022</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.210238</td>\n",
       "      <td>1.482053</td>\n",
       "      <td>2.346890</td>\n",
       "      <td>2.87158</td>\n",
       "      <td>1.571005</td>\n",
       "      <td>-2.552256</td>\n",
       "      <td>-1.623241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mpg  cylinders  displacement horsepower    weight  accerleration  \\\n",
       "0 -0.697747   1.482053      1.075915   0.663285  0.619748      -1.283618   \n",
       "1 -1.082115   1.482053      1.486832    1.57258  0.842258      -1.464852   \n",
       "2 -0.697747   1.482053      1.181033    1.18288  0.539692      -1.646086   \n",
       "3 -0.953992   1.482053      1.047246    1.18288  0.536160      -1.283618   \n",
       "4 -0.825870   1.482053      1.028134   0.923085  0.554997      -1.827320   \n",
       "5 -1.082115   1.482053      2.241772    2.42992  1.605147      -2.008554   \n",
       "6 -1.210238   1.482053      2.480677    3.00148  1.620452      -2.371022   \n",
       "7 -1.210238   1.482053      2.346890    2.87158  1.571005      -2.552256   \n",
       "\n",
       "   model year origin  \n",
       "0   -1.623241      1  \n",
       "1   -1.623241      1  \n",
       "2   -1.623241      1  \n",
       "3   -1.623241      1  \n",
       "4   -1.623241      1  \n",
       "5   -1.623241      1  \n",
       "6   -1.623241      1  \n",
       "7   -1.623241      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Question 3: a. Clean the data, removing samples with empty entries and scaling each feature to have zero mean and unit variance\n",
    "\n",
    "Step 4: Rewrite horsepower into its standardized form.\n",
    "\n",
    "Centralize the data by subtracting the mean, then devide the data with standard deviation. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "mean = df['horsepower'].mean()\n",
    "std = df['horsepower'].std()\n",
    "df['horsepower'] = (df['horsepower']-mean)/std\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 0.046677   -0.08986849  0.30446999 -0.06381986  0.35855809 -0.22516793\n",
      "  0.09657048  0.12859745 -0.7553884 ]\n",
      "Mean squared error: 0.17\n",
      "\n",
      "Sum of squared error, aka residual sum of squares.: 6.82\n",
      "\n",
      "Variance score: 0.82\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Step 5: \n",
    "\n",
    "i.  DictVectorization for categorical features, aka 'origins'. \n",
    "ii. Fit the model with LiearRegression() to get the best model for all features. \n",
    "\n",
    "Noted that I used the train_test_split here to split up the dataset, the test size is set to be 10% of the total data.\n",
    "In such way I expected to make it more comparable with the 10-fold CV. \n",
    "\n",
    "\"\"\"\n",
    "np.random.seed(0)\n",
    "\n",
    "# Feature columns:\n",
    "col = ['cylinders', 'displacement', 'horsepower', 'weight', 'accerleration', 'model year', 'origin']\n",
    "\n",
    "# Create original X and y:\n",
    "Original_X = df[col]\n",
    "Original_y = df['mpg']\n",
    "\n",
    "# Dict_Vectorize the X: \n",
    "dict_data = Original_X.T.to_dict().values()\n",
    "\n",
    "# Initiate vectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Transform X and y: y does not need to transform. \n",
    "X = vectorizer.fit_transform(dict_data)\n",
    "y = Original_y\n",
    "\n",
    "# Use tran_test_split from sklearn to split the test and train. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print()\n",
    "\n",
    "# Sum of squared error, aka residual sum of squares. \n",
    "print(\"Sum of squared error, aka residual sum of squares.: %.2f\"\n",
    "      % ((mean_squared_error(y_test, y_pred))*len(y_test)))\n",
    "print()\n",
    "\n",
    "#print(\"Residual Sum of squares: %.2f\" % np.mean((y_pred - y_test) ** 2))\n",
    "\n",
    "# Explained variance score: a result of 1 denotes a perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for all coefficients is:\n",
      "-666.4561468340506 \n",
      "BIC for all coefficients is:\n",
      "-634.686052115727 \n",
      "*******************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Calculate the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for two models\n",
    "– one with all coefficients  \n",
    "\n",
    "Step 6: AIC and BIC for all features. Should also be with all data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Fit all data:\n",
    "# Create original X and y:\n",
    "Original_X = df[col]\n",
    "Original_y = df['mpg']\n",
    "\n",
    "# Dict_Vectorize the X: \n",
    "dict_data = Original_X.T.to_dict().values()\n",
    "\n",
    "# Initiate vectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Transform X and y: y does not need to transform. \n",
    "X = vectorizer.fit_transform(dict_data)\n",
    "y = Original_y\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X, y)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X)\n",
    "\n",
    "\n",
    "k = 7+1\n",
    "n = len(y)\n",
    "\n",
    "mean_sq_er_total = mean_squared_error(y, y_pred)\n",
    "\n",
    "# AIC and BIC for All coefficients\n",
    "aic_total = (2*k) + n * np.log(mean_sq_er_total)\n",
    "print(\"AIC for all coefficients is:\\n{} \".format(aic_total))\n",
    "bic_total = k * np.log(n) + n * np.log(mean_sq_er_total)\n",
    "print(\"BIC for all coefficients is:\\n{} \".format(bic_total))\n",
    "print(\"*******************************************\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 0.42332854]]\n",
      "Mean squared error: 0.82\n",
      "\n",
      "Sum of squared error, aka residual sum of squares.: 32.75\n",
      "\n",
      "Variance score: 0.18\n",
      "\n",
      "AIC for all coefficients is:\n",
      "-74.41516012147483 \n",
      "BIC for all coefficients is:\n",
      "-66.4726364418939 \n",
      "*******************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Calculate the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for two models\n",
    "– one with one coefficient  \n",
    "\n",
    "Step 7: AIC and BIC for one feature. These are statistical methods, so I fitted the model with all samples. \n",
    "\n",
    "From above I know that \"weight\" has the most significant magnitute in coefficient.\n",
    "Then X will be weight in this question. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Independent variable dataframe X.\n",
    "# X = df['accerleration'][:, np.newaxis]\n",
    "X = df['accerleration'][:, np.newaxis]\n",
    "\n",
    "y = df['mpg'][:, np.newaxis]\n",
    "\n",
    "# Use tran_test_split from sklearn to split the test and train. \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Fill the model using all samples\n",
    "regr.fit(X, y)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y, y_pred))\n",
    "print()\n",
    "\n",
    "# Sum of squared error, aka residual sum of squares. \n",
    "print(\"Sum of squared error, aka residual sum of squares.: %.2f\"\n",
    "      % ((mean_squared_error(y, y_pred))*len(y_test)))\n",
    "print()\n",
    "\n",
    "# Explained variance score: a result of 1 denotes a perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y, y_pred))\n",
    "print()\n",
    "\n",
    "# BIC and AIC: \n",
    "k = 1+1\n",
    "n = len(y)\n",
    "\n",
    "mean_sq_er_total = mean_squared_error(y, y_pred)\n",
    "\n",
    "# AIC and BIC for All coefficients\n",
    "aic_total = (2*k) + n * np.log(mean_sq_er_total)\n",
    "print(\"AIC for all coefficients is:\\n{} \".format(aic_total))\n",
    "bic_total = k * np.log(n) + n * np.log(mean_sq_er_total)\n",
    "print(\"BIC for all coefficients is:\\n{} \".format(bic_total))\n",
    "print(\"*******************************************\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Step 8: Find a better model based on AIC and BIC. \n",
    "\n",
    "1. Define a function to iterate through given numbers of independent variable,\n",
    "and return variable combinations. \n",
    "   a). I set 'weight' as the main independent variable, since it has the highest coefficient.\n",
    "   b). To simplify the problem, I only use 2 and 6 features, which means to select 1 and 5 variables from list, since there is already a 'weight'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def models(size):\n",
    "    # Define other independent variables for me to choose from. \n",
    "    Ind = [\"cylinders\", \"displacement\", \"horsepower\", \"accerleration\", \"model year\", \"origin\"]\n",
    "    # Create the combinations for chosen number of variables. \n",
    "    lst_select = list(itertools.combinations(Ind,size))\n",
    "    print(\"Model Selected:\")\n",
    "    print()\n",
    "\n",
    "    # Create the final model selection list. \n",
    "    lst_models = []\n",
    "    for ele in lst_select:\n",
    "        lst_main = [\"weight\"]\n",
    "        lst_main.extend(ele)\n",
    "        lst_models.append(lst_main)\n",
    "\n",
    "\n",
    "    print()\n",
    "    return lst_models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Step 8: Find a better model based on AIC and BIC. \n",
    "\n",
    "Fit the model with all instances. \n",
    "\n",
    "2. Define a function to perform linear regression and caculate the AIC and BIC.\n",
    "   a). I set 'weight' as the main independent variable, since it has the highest coefficient.\n",
    "   b). To simplify the problem, I only use 2 and 5 features, which means to select 1 and 4 variables from list, since there is already a 'weight'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def Linear_IC(model):\n",
    "    for m in model:\n",
    "        Original_X = df[m]\n",
    "        Original_y = df['mpg']\n",
    "        \n",
    "        # Dict_Vectorize the X: \n",
    "        dict_data = Original_X.T.to_dict().values()\n",
    "\n",
    "        # Initiate vectorizer\n",
    "        vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "        # Transform X and y: y does not need to transform. \n",
    "        X = vectorizer.fit_transform(dict_data)\n",
    "        # y does not need to be vectorized, since this is a numerical column.\n",
    "        y = Original_y\n",
    "        # Use tran_test_split from sklearn to split the test and train. \n",
    "        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "\n",
    "        # Create linear regression object\n",
    "        regr = linear_model.LinearRegression()\n",
    "\n",
    "        # Train the model using the training sets\n",
    "        regr.fit(X, y)\n",
    "\n",
    "        # Make predictions using the testing set\n",
    "        y_pred = regr.predict(X)\n",
    "        \n",
    "        k = len(model)+1\n",
    "        n = len(y)\n",
    "\n",
    "        mean_sq_er_total = mean_squared_error(y, y_pred)\n",
    "\n",
    "        # AIC and BIC for All coefficients\n",
    "        aic_total = (2*k) + n * np.log(mean_sq_er_total)\n",
    "        print(\"AIC for {} is:\\n{} \".format(m, aic_total))\n",
    "        bic_total = k * np.log(n) + n * np.log(mean_sq_er_total)\n",
    "        print(\"BIC for {} is:\\n{} \".format(m, bic_total))\n",
    "        print(\"*******************************************\")\n",
    "        print()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Step 9. 10-fold cross validation\n",
    "\n",
    "Define a class CrossValidation(), and inside the class, define the function k_fold(k, model_list):\n",
    "k - number of folds;\n",
    "model_list: the list containing the column names for the selected features. \n",
    "\n",
    "Noted that this class should only be used after the dataframe is defined, cleaned and named as 'df'.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class CrossValidation_Manually():\n",
    "    \n",
    "    def __init__(self, model_list): \n",
    "        self.inst_attr = \"Selected Features for Cross Validation.\" \n",
    "        self.model_list = model_list\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(print(\"Selected features: \\n{}\".format(self.model_list)))\n",
    "\n",
    "    \n",
    "    def K_fold(self):\n",
    "        \n",
    "        self.R2_Manually = []\n",
    "        self.MSE_Manually = []\n",
    "        \n",
    "        for i in range(10):\n",
    "            print(\"****************Fold {} as the test dataset*******************\".format(i))\n",
    "\n",
    "            # Noted that before execute the function, I need the data after the extra datapoints taken out. \n",
    "            # Namely, I have df_new and df_target_new. \n",
    "            n = len(df_target_new)\n",
    "            array = np.arange(n).reshape((n, 1))\n",
    "            #print(array)\n",
    "\n",
    "            split = np.vsplit(array, 10)\n",
    "\n",
    "            # Create linear regression object\n",
    "            regr = linear_model.LinearRegression()\n",
    "        \n",
    "            X_train = np.delete(np.array(df_new), (split[i].tolist()), axis=0)\n",
    "            \n",
    "            X_step_1 = np.array(df_new)[split[i].tolist(),]\n",
    "            X_test = np.squeeze(X_step_1)\n",
    "\n",
    "            y_train = np.delete(np.array(df_target_new), (split[i].tolist()), axis=0)\n",
    "        \n",
    "            y_step_1 = np.array(df_target_new)[split[i].tolist(),]  \n",
    "            y_test = np.squeeze(y_step_1)\n",
    "    \n",
    "            regr.fit(X_train, y_train)\n",
    "    \n",
    "            y_pred = regr.predict(X_test)\n",
    "    \n",
    "            print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "            # The mean squared error\n",
    "            print(\"Mean squared error: %.2f\"\n",
    "                  % mean_squared_error(y_test, y_pred))\n",
    "            self.MSE_Manually.append(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "            # Explained variance score: a result of 1 denotes a perfect prediction\n",
    "            print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "            self.R2_Manually.append(r2_score(y_test, y_pred))\n",
    "    \n",
    "            print()\n",
    "\n",
    "    # For further questions in logistic regression.\n",
    "    def K_fold_logreg(self):\n",
    "        \n",
    "        #self.R2_logreg = []\n",
    "        self.MSE_logreg = []\n",
    "        self.score_logreg = []\n",
    "        self.accuracy_logreg = []\n",
    "        \n",
    "        for i in range(10):\n",
    "            print(\"****************Fold {} as the test dataset*******************\".format(i))\n",
    "\n",
    "            # Noted that before execute the function, I need the data after the extra datapoints taken out. \n",
    "            # Namely, I have df_new and df_target_new. \n",
    "            n = len(df_target_new)\n",
    "            array = np.arange(n).reshape((n, 1))\n",
    "            #print(array)\n",
    "\n",
    "            split = np.vsplit(array, 10)\n",
    "            \n",
    "            # Train and test data:\n",
    "            X_train = np.delete(np.array(df_new), (split[i].tolist()), axis=0)\n",
    "            \n",
    "            X_step_1 = np.array(df_new)[split[i].tolist(),]\n",
    "            X_test = np.squeeze(X_step_1)\n",
    "\n",
    "            y_train = np.delete(np.array(df_target_new), (split[i].tolist()), axis=0)\n",
    "        \n",
    "            y_step_1 = np.array(df_target_new)[split[i].tolist(),]  \n",
    "            y_test = np.squeeze(y_step_1)\n",
    "    \n",
    "            # Initiate logistic regression model:\n",
    "            logreg = linear_model.LogisticRegression(C=1e5)\n",
    "            \n",
    "            logreg.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = logreg.predict(X_test)\n",
    "\n",
    "            #print(\"Prediction: {}\".format(y_pred))\n",
    "\n",
    "            print(\"Logistic Regression Score with LogisticRegression.scoore(): {}\".format(logreg.score(X_test, y_test)))\n",
    "            self.score_logreg.append(logreg.score(X_test, y_test))\n",
    "            print()\n",
    "            \n",
    "            print(\"Logistic Regression Score with Metrics.accuracy_score(): {}\".format(accuracy_score(y_test, y_pred)))\n",
    "            self.accuracy_logreg.append(accuracy_score(y_test, y_pred))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many data points to be droped, I need the shape of vectorized data:\n",
      "(392, 8)\n",
      "The shape of new data:\n",
      "(390, 8)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Use 10-fold cross validation and MSE as a metric to select among these three  models. Manually Method.\n",
    "\n",
    "Model 1: ['weight', 'cylinders', 'displacement', 'horsepower', 'model year', 'origin'] since the AIC and BIC are the smallest, suggesting a good fit:\n",
    "\n",
    "Step 1: Since I am going to use 10-folds manually, I need to drop extra data points with the Victorized matrix.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Original_X = df[['weight', 'cylinders', 'displacement', 'horsepower', 'model year', 'origin']]\n",
    "Original_y = df['mpg']\n",
    "# Dict_Vectorize the X: \n",
    "dict_data = Original_X.T.to_dict().values()\n",
    "\n",
    "# Initiate vectorizer\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Transform X and y: y does not need to transform. \n",
    "X = pd.DataFrame(vectorizer.fit_transform(dict_data))\n",
    "y = Original_y\n",
    "\n",
    "print(\"To determine how many data points to be droped, I need the shape of vectorized data:\\n{}\".format(X.shape))\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "# Set the number of samples to be removed.\n",
    "remove_n = 2\n",
    "\n",
    "# Randomly choose remove_n number of index from dataframe.\n",
    "drop = np.random.choice(df.index, remove_n, replace=False)\n",
    "\n",
    "# Drop rows that are randomly chosen based on indexes, for fearure data.\n",
    "df_new = X.drop(drop)\n",
    "\n",
    "# Drop the same rows in target data.\n",
    "# Write target into panda dataframe for easier furthur process.\n",
    "df_target_new = y.drop(drop)\n",
    "\n",
    "print(\"The shape of new data:\\n{}\".format(df_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Fold 0 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.10787796  0.33716095 -0.185793    0.40050197 -0.24389737  0.10558049\n",
      "  0.13831689 -0.68280928]\n",
      "Mean squared error: 0.16\n",
      "Variance score: 0.65\n",
      "\n",
      "****************Fold 1 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.13991014  0.31472152 -0.10714193  0.38044561 -0.2249957   0.10093149\n",
      "  0.12406422 -0.71582277]\n",
      "Mean squared error: 0.15\n",
      "Variance score: 0.77\n",
      "\n",
      "****************Fold 2 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.10415255  0.29695365 -0.14149993  0.34373634 -0.22552212  0.07906398\n",
      "  0.14645814 -0.71160246]\n",
      "Mean squared error: 0.16\n",
      "Variance score: 0.66\n",
      "\n",
      "****************Fold 3 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.14413236  0.38894516 -0.14398435  0.35870711 -0.25047262  0.12718146\n",
      "  0.12329117 -0.72871381]\n",
      "Mean squared error: 0.15\n",
      "Variance score: 0.76\n",
      "\n",
      "****************Fold 4 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.118021    0.32459559 -0.11580741  0.36307947 -0.23838452  0.11662124\n",
      "  0.12176328 -0.72148744]\n",
      "Mean squared error: 0.09\n",
      "Variance score: 0.76\n",
      "\n",
      "****************Fold 5 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.10493051  0.29780577 -0.12721867  0.36964405 -0.25060539  0.1106865\n",
      "  0.13991889 -0.67240815]\n",
      "Mean squared error: 0.11\n",
      "Variance score: 0.85\n",
      "\n",
      "****************Fold 6 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.09575303  0.25392961 -0.07891874  0.38348683 -0.25451196  0.10558648\n",
      "  0.14892548 -0.67183384]\n",
      "Mean squared error: 0.28\n",
      "Variance score: 0.61\n",
      "\n",
      "****************Fold 7 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.09256317  0.28609515 -0.1238086   0.36637712 -0.25630373  0.10728439\n",
      "  0.14901934 -0.66172614]\n",
      "Mean squared error: 0.20\n",
      "Variance score: 0.77\n",
      "\n",
      "****************Fold 8 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.1517708   0.27142845 -0.07203008  0.33298426 -0.16388255  0.0611369\n",
      "  0.10274565 -0.68119881]\n",
      "Mean squared error: 0.48\n",
      "Variance score: 0.19\n",
      "\n",
      "****************Fold 9 as the test dataset*******************\n",
      "Coefficients: \n",
      " [-0.09570753  0.22678887 -0.08688184  0.35489225 -0.22094543  0.07021975\n",
      "  0.15072568 -0.66579548]\n",
      "Mean squared error: 0.24\n",
      "Variance score: 0.56\n",
      "\n",
      "Mean R2 for Manually generated 10-fold:\n",
      "0.6585628893615294\n",
      "\n",
      "Mean MSE for Manually generated 10-fold:\n",
      "0.201592421521993\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Use 10-fold cross validation and MSE as a metric to select among these three  models. Manually Method.\n",
    "\n",
    "Model 1: ['weight', 'cylinders', 'displacement', 'horsepower', 'model year', 'origin'] since the AIC and BIC are the smallest, suggesting a good fit:\n",
    "\n",
    "Step 2: Use the Class CrossValidation_Manually for ['weight', 'cylinders', 'displacement', 'horsepower', 'model year', 'origin'].\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "CV = CrossValidation_Manually(['weight', 'cylinders', 'displacement', 'horsepower', 'model year', 'origin'])\n",
    "CV.K_fold()\n",
    "#print(CV.R2_Manually)\n",
    "print(\"Mean R2 for Manually generated 10-fold:\\n{}\".format(np.mean(CV.R2_Manually)))\n",
    "print()\n",
    "#print(CV.MSE_Manually)\n",
    "print(\"Mean MSE for Manually generated 10-fold:\\n{}\".format(np.mean(CV.MSE_Manually)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
